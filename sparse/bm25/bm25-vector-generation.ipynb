{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search with BM25 Sparse Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "BM25 is a popular technique for retrieving text. It uses term frequencies to determine the relative importance of the term to the query. It is a simple but effective and only requires knowing the number of documents in a corpus and the frequency of terms across documents. In the following guide we will show how to use BM25 with Pinecone's sparse-dense index for use in hybrid search.\n",
    "\n",
    "Skip the embedding creation step by using the [companion guide]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "          'pinecone-client[grpc]' \\\n",
    "          transformers \\\n",
    "          torch \\\n",
    "          sentence_transformers \\\n",
    "          spacy \\\n",
    "          scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pinecone\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pinecone_text.py' ,'w') as fb:\n",
    "    fb.write(requests.get('https://gist.githubusercontent.com/gdj0nes/8bf4f85df522a8b1454754eec284691d/raw/183b60fced37bcb64b206182cb80bca9fe5fe8e2/pinecone_text.py').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora Dataset\n",
    "\n",
    "Load the popular Quora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample = 10_000\n",
    "df = pd.read_parquet('https://storage.googleapis.com/gareth-pinecone-datasets/quora-bm25.parquet', columns=['id', 'text'])\n",
    "df = df.sample(n=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163020</th>\n",
       "      <td>168111</td>\n",
       "      <td>What are some good movies based on real life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409526</th>\n",
       "      <td>421603</td>\n",
       "      <td>Does the multiverse really exists?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107223</th>\n",
       "      <td>110619</td>\n",
       "      <td>What tie and pant should I wear with maroon s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25767</th>\n",
       "      <td>26565</td>\n",
       "      <td>What is the role of electrical engineer in me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429605</th>\n",
       "      <td>442225</td>\n",
       "      <td>Is Jio available for 3G?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text\n",
       "163020  168111   What are some good movies based on real life ...\n",
       "409526  421603                 Does the multiverse really exists?\n",
       "107223  110619   What tie and pant should I wear with maroon s...\n",
       "25767    26565   What is the role of electrical engineer in me...\n",
       "429605  442225                           Is Jio available for 3G?"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit BM25 with Spacy Tokenizer\n",
    "\n",
    "We'll create fit a BM25 model using Spacy to tokenize data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pinecone_text\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\", \"ner\"])\n",
    "\n",
    "def tokenizer(text):\n",
    "    return [token.text for token in nlp(text)]\n",
    "\n",
    "bm25 = pinecone_text.BM25(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to calculate how often tokens appear in documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.88 s, sys: 26.5 ms, total: 3.91 s\n",
      "Wall time: 3.91 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BM25(avgdl=13.2248,\n",
       "     doc_freq=[11.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "               21.0, 1.0, 1.0, 2.0, ...],\n",
       "     ndocs=10000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bm25.fit(df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Model\n",
    "\n",
    "We use the popular all-MiniLM-L6-v2 model available on HuggingFace for dense vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Dense & Sparse Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.25 s, sys: 353 ms, total: 7.61 s\n",
      "Wall time: 7.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['sparse_values'] = df['text'].apply(bm25.transform_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 32s, sys: 6.79 s, total: 5min 39s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['values'] = df['text'].apply(lambda x: model.encode(x).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsert to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# Init Pinecone\n",
    "api_key = os.getenv('PINECONE_API_KEY') or None\n",
    "environment = None\n",
    "if (api_key is None) or (environment is None):\n",
    "    raise ValueError('You must specify an environment and API Key')\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=api_key,\n",
    "    environment=\"internal-beta\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"bm25-embeddings\"\n",
    "batch_size = 300\n",
    "dimension = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.create_index(\n",
    "    index_name,\n",
    "    pod_type='s1',\n",
    "    metric='dotproduct',\n",
    "    dimension=dimension,\n",
    "    metadata_config={\"indexed\": []}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:04<00:00,  7.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from pinecone import GRPCVector, GRPCSparseValues\n",
    "from google.protobuf.struct_pb2 import Struct\n",
    "\n",
    "with pinecone.GRPCIndex(index_name) as index:\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch = df[i:min(i+batch_size, len(df))].to_dict(orient='records')\n",
    "        upserts = []\n",
    "        for row in batch:\n",
    "            metadata = Struct()\n",
    "            metadata.update(dict(text=row['text']))\n",
    "            u = GRPCVector(\n",
    "                id=str(row['id']),\n",
    "                values=row['values'],\n",
    "                metadata=metadata,\n",
    "                sparse_values=GRPCSparseValues(\n",
    "                    indices=row['sparse_values']['indices'],\n",
    "                    values=row['sparse_values']['values']\n",
    "                )\n",
    "            )\n",
    "            upserts.append(u)\n",
    "        index.upsert(vectors=upserts, async_req=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Queries with BM25\n",
    "\n",
    "We can fetch records by calculating distance over both sparse and dense vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_score_norm(dense, sparse, alpha: float):\n",
    "    \"\"\"Hybrid score using a convex combination\n",
    "\n",
    "    alpha * dense + (1 - alpha) * sparse\n",
    "\n",
    "    Args:\n",
    "        dense: Array of floats representing\n",
    "        sparse: a dict of `indices` and `values`\n",
    "        alpha: scale between 0 and 1\n",
    "    \"\"\"\n",
    "    if alpha < 0 or alpha > 1:\n",
    "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "    hs = {\n",
    "        'indices': sparse['indices'],\n",
    "        'values':  [v * (1 - alpha) for v in sparse['values']]\n",
    "    }\n",
    "    return [v * alpha for v in dense], hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import SparseValues\n",
    "\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"nyc bar\"\n",
    "sparse = bm25.transform_query(text)\n",
    "dense = model.encode(text).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '447471',\n",
       "  'metadata': {'text': ' How much does a gold bar mill cost?'},\n",
       "  'score': 0.216695413,\n",
       "  'values': []},\n",
       " {'id': '327836',\n",
       "  'metadata': {'text': ' What is the meaning of water resistant 10 bar?'},\n",
       "  'score': 0.208496243,\n",
       "  'values': []},\n",
       " {'id': '124618',\n",
       "  'metadata': {'text': ' What are some bars in NYC that do not card?'},\n",
       "  'score': 0.200894922,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdense, hsparse = hybrid_score_norm(dense, sparse, 0.0)\n",
    "index.query(top_k=3, vector=hdense, sparse_vector=SparseValues(**hsparse), include_metadata=True)['matches']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '124618',\n",
       "  'metadata': {'text': ' What are some bars in NYC that do not card?'},\n",
       "  'score': 0.332611889,\n",
       "  'values': []},\n",
       " {'id': '447471',\n",
       "  'metadata': {'text': ' How much does a gold bar mill cost?'},\n",
       "  'score': 0.23921828,\n",
       "  'values': []},\n",
       " {'id': '476354',\n",
       "  'metadata': {'text': \" Why don't people post flyers in the NYC subway?\"},\n",
       "  'score': 0.237853348,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdense, hsparse = hybrid_score_norm(dense, sparse, 0.25)\n",
    "index.query(top_k=3, vector=hdense, sparse_vector=SparseValues(**hsparse), include_metadata=True)['matches']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '124618',\n",
       "  'metadata': {'text': ' What are some bars in NYC that do not card?'},\n",
       "  'score': 0.727762818,\n",
       "  'values': []},\n",
       " {'id': '498343',\n",
       "  'metadata': {'text': ' What are bars in rap music?'},\n",
       "  'score': 0.550006151,\n",
       "  'values': []},\n",
       " {'id': '254425',\n",
       "  'metadata': {'text': ' What is the best colocation center in New York?'},\n",
       "  'score': 0.504735351,\n",
       "  'values': []}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdense, hsparse = hybrid_score_norm(dense, sparse, 1.0)\n",
    "index.query(top_k=3, vector=hdense, sparse_vector=SparseValues(**hsparse), include_metadata=True)['matches']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
