{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/sparse/splade/splade-queries.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/sparse/splade/splade-queries.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse-Dense Vector Search with SPLADE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "SPLADE is a class of models that produce sparse embeddings. Unlike dense embeddings which can be difficult to interpret sparse embeddings map to tokens for easier interpretability. SPLADE models have been shown to consistently outperform dense models, particularly in out-of-domain settings.\n",
    "\n",
    "The following guide will show you how to construct SPLADE embeddings to use with Pinecone's sparse-dense index. See the [companion guide]() to learn how to generate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "          git+https://git@github.com/pinecone-io/pinecone-python-client.git#egg=pinecone-client[grpc] \\\n",
    "          polars \\\n",
    "          transformers \\\n",
    "          torch \\\n",
    "          sentence_transformers \\\n",
    "          gcsfs \\\n",
    "          pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Pinecone\n",
    "api_key = os.getenv('PINECONE_API_KEY') or None\n",
    "environment = None\n",
    "if (api_key is None) or (environment is None):\n",
    "    raise ValueError('You must specify an environment and API Key')\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=api_key,\n",
    "    environment=environment\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora Dataset\n",
    "\n",
    "Load the popular Quora dataset with embeddings precomputed using\n",
    "\n",
    "* Dense: [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "* Sparse: [naver/splade-cocondenser-ensembledistil](https://huggingface.co/naver/splade-cocondenser-ensembledistil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet('https://storage.googleapis.com/gareth-pinecone-datasets/quora.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       ".pl-dataframe > thead > tr > th {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<table border=\"1\" class=\"pl-dataframe\">\n",
       "<small>shape: (5, 4)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "values\n",
       "</th>\n",
       "<th>\n",
       "id\n",
       "</th>\n",
       "<th>\n",
       "sparse_values\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "list[f32]\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "struct[2]\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "[0.402489, -0.234254, ... 0.222465]\n",
       "</td>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "<td>\n",
       "{[0.08416, 0.055447, ... 0.197036],[1012, 2000, ... 20138]}\n",
       "</td>\n",
       "<td>\n",
       "&quot; What is the s...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "[0.511194, -0.198763, ... 0.238244]\n",
       "</td>\n",
       "<td>\n",
       "2\n",
       "</td>\n",
       "<td>\n",
       "{[0.189603, 0.21525, ... 0.147162],[1000, 1012, ... 20138]}\n",
       "</td>\n",
       "<td>\n",
       "&quot; What is the s...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "[-0.223715, 0.741517, ... 0.191113]\n",
       "</td>\n",
       "<td>\n",
       "3\n",
       "</td>\n",
       "<td>\n",
       "{[0.134441, 0.188095, ... 0.021336],[1005, 1006, ... 17070]}\n",
       "</td>\n",
       "<td>\n",
       "&quot; What is the s...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "[-0.37124, 0.709703, ... -0.049561]\n",
       "</td>\n",
       "<td>\n",
       "4\n",
       "</td>\n",
       "<td>\n",
       "{[0.029134, 0.360959, ... 0.042988],[1005, 1011, ... 21156]}\n",
       "</td>\n",
       "<td>\n",
       "&quot; What would ha...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "[-0.166566, 0.218813, ... -0.097715]\n",
       "</td>\n",
       "<td>\n",
       "5\n",
       "</td>\n",
       "<td>\n",
       "{[0.033697, 0.44331, ... 0.629484],[2006, 2017, ... 21628]}\n",
       "</td>\n",
       "<td>\n",
       "&quot; How can I inc...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────────────────────┬─────┬───────────────────────────┬────────────────────────────────────┐\n",
       "│ values                    ┆ id  ┆ sparse_values             ┆ text                               │\n",
       "│ ---                       ┆ --- ┆ ---                       ┆ ---                                │\n",
       "│ list[f32]                 ┆ i64 ┆ struct[2]                 ┆ str                                │\n",
       "╞═══════════════════════════╪═════╪═══════════════════════════╪════════════════════════════════════╡\n",
       "│ [0.402489, -0.234254, ... ┆ 1   ┆ {[0.08416, 0.055447, ...  ┆ What is the step by step guide ... │\n",
       "│ 0.2224...                 ┆     ┆ 0.19703...                ┆                                    │\n",
       "│ [0.511194, -0.198763, ... ┆ 2   ┆ {[0.189603, 0.21525, ...  ┆ What is the step by step guide ... │\n",
       "│ 0.2382...                 ┆     ┆ 0.14716...                ┆                                    │\n",
       "│ [-0.223715, 0.741517, ... ┆ 3   ┆ {[0.134441, 0.188095, ... ┆ What is the story of Kohinoor (... │\n",
       "│ 0.1911...                 ┆     ┆ 0.0213...                 ┆                                    │\n",
       "│ [-0.37124, 0.709703, ...  ┆ 4   ┆ {[0.029134, 0.360959, ... ┆ What would happen if the Indian... │\n",
       "│ -0.0495...                ┆     ┆ 0.0429...                 ┆                                    │\n",
       "│ [-0.166566, 0.218813, ... ┆ 5   ┆ {[0.033697, 0.44331, ...  ┆ How can I increase the speed of... │\n",
       "│ -0.097...                 ┆     ┆ 0.62948...                ┆                                    │\n",
       "└───────────────────────────┴─────┴───────────────────────────┴────────────────────────────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"splade-embedding-query\"\n",
    "batch_size = 300\n",
    "dimension = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.create_index(\n",
    "    index_name,\n",
    "    pod_type='s1',\n",
    "    metric='dotproduct',\n",
    "    dimension=dimension,\n",
    "    metadata_config={\"indexed\": []}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1744/1744 [03:50<00:00,  7.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from pinecone import GRPCVector, GRPCSparseValues\n",
    "from google.protobuf.struct_pb2 import Struct\n",
    "\n",
    "with pinecone.GRPCIndex(index_name) as index:\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch = df[i:min(i+batch_size, len(df))]\n",
    "        upserts = []\n",
    "        for row in batch.rows(named=True):\n",
    "            metadata = Struct()\n",
    "            metadata.update(dict(text=row['text']))\n",
    "            u = GRPCVector(\n",
    "                values=row['values'],\n",
    "                id=str(row['id']),\n",
    "                metadata=metadata,\n",
    "                sparse_values=GRPCSparseValues(**row['sparse_values'])\n",
    "            )\n",
    "            upserts.append(u)\n",
    "        index.upsert(vectors=upserts, async_req=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse-Dense Queries with SPLADE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "class SPLADE:\n",
    "    def __init__(self, model):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(model)\n",
    "\n",
    "    def __call__(self, text: str):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits\n",
    "\n",
    "        inter = torch.log1p(torch.relu(logits[0]))\n",
    "        token_max = torch.max(inter, dim=0)  # sum over input tokens\n",
    "        nz_tokens = torch.where(token_max.values > 0)[0]\n",
    "        nz_weights = token_max.values[nz_tokens]\n",
    "\n",
    "        order = torch.sort(nz_weights, descending=True)\n",
    "        nz_weights = nz_weights[order[1]]\n",
    "        nz_tokens = nz_tokens[order[1]]\n",
    "        return {'indices': nz_tokens.numpy().tolist(), 'values': nz_weights.numpy().tolist()}\n",
    "\n",
    "def hybrid_score_norm(dense, sparse, alpha: float):\n",
    "    \"\"\"Hybrid score using a convex combination\n",
    "\n",
    "    alpha * dense + (1 - alpha) * sparse\n",
    "\n",
    "    Args:\n",
    "        dense: Array of floats representing\n",
    "        sparse: a dict of `indices` and `values`\n",
    "        alpha: scale between 0 and 1\n",
    "    \"\"\"\n",
    "    if alpha < 0 or alpha > 1:\n",
    "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "    hs = {\n",
    "        'indices': sparse['indices'],\n",
    "        'values':  [v * (1 - alpha) for v in sparse['values']]\n",
    "    }\n",
    "    return [v * alpha for v in dense], hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "splade = SPLADE(\"naver/splade-cocondenser-ensembledistil\")\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"what is the capital of france\"\n",
    "sparse = splade(text)\n",
    "dense = model.encode(text).tolist()\n",
    "hdense, hsparse = hybrid_score_norm(dense, sparse, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '29784',\n",
       "              'metadata': {'text': ' What is the capital city of France?'},\n",
       "              'score': 9.20412,\n",
       "              'values': []},\n",
       "             {'id': '184797',\n",
       "              'metadata': {'text': ' What are best tourist spots in france?'},\n",
       "              'score': 6.47260284,\n",
       "              'values': []},\n",
       "             {'id': '380665',\n",
       "              'metadata': {'text': ' What is France famous for?'},\n",
       "              'score': 6.34292221,\n",
       "              'values': []},\n",
       "             {'id': '380666',\n",
       "              'metadata': {'text': ' What is France most famous for?'},\n",
       "              'score': 6.23249435,\n",
       "              'values': []},\n",
       "             {'id': '223775',\n",
       "              'metadata': {'text': ' Is France safe to visit?'},\n",
       "              'score': 6.20398569,\n",
       "              'values': []},\n",
       "             {'id': '99552',\n",
       "              'metadata': {'text': ' What are some popular landmarks in '\n",
       "                                   'France?'},\n",
       "              'score': 6.11965084,\n",
       "              'values': []},\n",
       "             {'id': '148793',\n",
       "              'metadata': {'text': ' Is there anyone who lives in France?'},\n",
       "              'score': 6.03068352,\n",
       "              'values': []},\n",
       "             {'id': '126779',\n",
       "              'metadata': {'text': ' How can I get a job in France?'},\n",
       "              'score': 5.9193182,\n",
       "              'values': []},\n",
       "             {'id': '45604',\n",
       "              'metadata': {'text': ' What are the top Universities in France?'},\n",
       "              'score': 5.90843773,\n",
       "              'values': []},\n",
       "             {'id': '198948',\n",
       "              'metadata': {'text': ' What are some interesting facts about '\n",
       "                                   'France beyond Paris?'},\n",
       "              'score': 5.80534887,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import SparseValues\n",
    "\n",
    "index.query(top_k=10, vector=hdense, sparse_vector=SparseValues(**hsparse), include_metadata=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
