{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/sparse/splade/splade-embedding-generation.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/sparse/splade/splade-embedding-generation.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLADE Sparse-Dense Embedding Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "SPLADE is a class of models that produce sparse embeddings. Unlike dense embeddings which can be difficult to interpret sparse embeddings map to tokens for easier interpretability. SPLADE models have been shown to consistently outperform dense models, particularly in out-of-domain settings.\n",
    "\n",
    "The following guide will show you how to construct SPLADE embeddings to use with Pinecone's sparse-dense index. See the [companion guide]() to learn to skip embedding generation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \\\n",
    "          git+https://git@github.com/pinecone-io/pinecone-python-client.git#egg=pinecone-client[grpc] \\\n",
    "          polars \\\n",
    "          transformers \\\n",
    "          torch \\\n",
    "          sentence_transformers \\\n",
    "          gcsfs \\\n",
    "          pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Embeddings with SPLADE\n",
    "\n",
    "In the following example we will use. SPLADE Model: [naver/splade-cocondenser-ensembledistil](https://huggingface.co/naver/splade-cocondenser-ensembledistilhttps://huggingface.co/naver/splade-cocondenser-ensembledistil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "class SPLADE:\n",
    "    def __init__(self, model):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(model)\n",
    "\n",
    "    def __call__(self, text: str):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits\n",
    "\n",
    "        inter = torch.log1p(torch.relu(logits[0]))\n",
    "        token_max = torch.max(inter, dim=0)  # sum over input tokens\n",
    "        nz_tokens = torch.where(token_max.values > 0)[0]\n",
    "        nz_weights = token_max.values[nz_tokens]\n",
    "\n",
    "        order = torch.sort(nz_weights, descending=True)\n",
    "        nz_weights = nz_weights[order[1]]\n",
    "        nz_tokens = nz_tokens[order[1]]\n",
    "        return {'indices': nz_tokens.numpy().tolist(), 'values': nz_weights.numpy().tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "splade = SPLADE(\"naver/splade-cocondenser-ensembledistil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       ".pl-dataframe > thead > tr > th {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<table border=\"1\" class=\"pl-dataframe\">\n",
       "<small>shape: (10, 3)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "indices\n",
       "</th>\n",
       "<th>\n",
       "values\n",
       "</th>\n",
       "<th>\n",
       "tokens\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "3007\n",
       "</td>\n",
       "<td>\n",
       "3.099394\n",
       "</td>\n",
       "<td>\n",
       "&quot;capital&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "2605\n",
       "</td>\n",
       "<td>\n",
       "2.851794\n",
       "</td>\n",
       "<td>\n",
       "&quot;france&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "2413\n",
       "</td>\n",
       "<td>\n",
       "2.387511\n",
       "</td>\n",
       "<td>\n",
       "&quot;french&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "2885\n",
       "</td>\n",
       "<td>\n",
       "1.737867\n",
       "</td>\n",
       "<td>\n",
       "&quot;europe&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "9424\n",
       "</td>\n",
       "<td>\n",
       "1.73612\n",
       "</td>\n",
       "<td>\n",
       "&quot;capitol&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "2103\n",
       "</td>\n",
       "<td>\n",
       "1.334281\n",
       "</td>\n",
       "<td>\n",
       "&quot;city&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "10505\n",
       "</td>\n",
       "<td>\n",
       "0.802148\n",
       "</td>\n",
       "<td>\n",
       "&quot;geography&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "3000\n",
       "</td>\n",
       "<td>\n",
       "0.707464\n",
       "</td>\n",
       "<td>\n",
       "&quot;paris&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "8709\n",
       "</td>\n",
       "<td>\n",
       "0.678849\n",
       "</td>\n",
       "<td>\n",
       "&quot;michel&quot;\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "5288\n",
       "</td>\n",
       "<td>\n",
       "0.534112\n",
       "</td>\n",
       "<td>\n",
       "&quot;switzerland&quot;\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "┌─────────┬──────────┬─────────────┐\n",
       "│ indices ┆ values   ┆ tokens      │\n",
       "│ ---     ┆ ---      ┆ ---         │\n",
       "│ i64     ┆ f64      ┆ str         │\n",
       "╞═════════╪══════════╪═════════════╡\n",
       "│ 3007    ┆ 3.099394 ┆ capital     │\n",
       "│ 2605    ┆ 2.851794 ┆ france      │\n",
       "│ 2413    ┆ 2.387511 ┆ french      │\n",
       "│ 2885    ┆ 1.737867 ┆ europe      │\n",
       "│ ...     ┆ ...      ┆ ...         │\n",
       "│ 10505   ┆ 0.802148 ┆ geography   │\n",
       "│ 3000    ┆ 0.707464 ┆ paris       │\n",
       "│ 8709    ┆ 0.678849 ┆ michel      │\n",
       "│ 5288    ┆ 0.534112 ┆ switzerland │\n",
       "└─────────┴──────────┴─────────────┘"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = \"what is the capital of france?\"\n",
    "sparse_vector = splade(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "SPLADE query & document expansion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pl.DataFrame({\n",
    "    **sparse_vector,\n",
    "    **{'tokens': splade.tokenizer.convert_ids_to_tokens(sparse_vector['indices'])} # Fetch original tokens\n",
    "})[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Embeddings\n",
    "\n",
    "For dense embeddings we use a popular model from sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Quora Dataset\n",
    "\n",
    "Quora is a popular dataset for evaluating text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet('https://storage.googleapis.com/gareth-pinecone-datasets/quora.parquet').select([pl.col(['id', 'text'])]).head(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       ".pl-dataframe > thead > tr > th {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<table border=\"1\" class=\"pl-dataframe\">\n",
       "<small>shape: (10, 2)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "id\n",
       "</th>\n",
       "<th>\n",
       "text\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "1\n",
       "</td>\n",
       "<td>\n",
       "&quot; What is the s...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "2\n",
       "</td>\n",
       "<td>\n",
       "&quot; What is the s...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "3\n",
       "</td>\n",
       "<td>\n",
       "&quot; What is the s...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "4\n",
       "</td>\n",
       "<td>\n",
       "&quot; What would ha...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "5\n",
       "</td>\n",
       "<td>\n",
       "&quot; How can I inc...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "6\n",
       "</td>\n",
       "<td>\n",
       "&quot; How can Inter...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "7\n",
       "</td>\n",
       "<td>\n",
       "&quot; Why am I ment...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "8\n",
       "</td>\n",
       "<td>\n",
       "&quot; Find the rema...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "9\n",
       "</td>\n",
       "<td>\n",
       "&quot; Which one dis...\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "10\n",
       "</td>\n",
       "<td>\n",
       "&quot; Which fish wo...\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌─────┬─────────────────────────────────────┐\n",
       "│ id  ┆ text                                │\n",
       "│ --- ┆ ---                                 │\n",
       "│ i64 ┆ str                                 │\n",
       "╞═════╪═════════════════════════════════════╡\n",
       "│ 1   ┆  What is the step by step guide ... │\n",
       "│ 2   ┆  What is the step by step guide ... │\n",
       "│ 3   ┆  What is the story of Kohinoor (... │\n",
       "│ 4   ┆  What would happen if the Indian... │\n",
       "│ ... ┆ ...                                 │\n",
       "│ 7   ┆  Why am I mentally very lonely? ... │\n",
       "│ 8   ┆  Find the remainder when [math]2... │\n",
       "│ 9   ┆  Which one dissolve in water qui... │\n",
       "│ 10  ┆  Which fish would survive in sal... │\n",
       "└─────┴─────────────────────────────────────┘"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns([\n",
    "    pl.col('text').apply(lambda x: splade(x)).alias('sparse_values'),\n",
    "    pl.col('text').apply(lambda x: model.encode(x).tolist()).alias('values'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsert to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Pinecone API key\n",
    "import os\n",
    "import pinecone\n",
    "\n",
    "api_key = os.getenv('PINECONE_API_KEY') or None\n",
    "environment = None\n",
    "pinecone.init(\n",
    "    api_key=api_key,\n",
    "    environment=environment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"splade-embedding-generation\"\n",
    "batch_size = 300\n",
    "dimension = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.create_index(\n",
    "    index_name,\n",
    "    pod_type='s1',\n",
    "    metric='dotproduct',\n",
    "    dimension=dimension,\n",
    "    metadata_config={\"indexed\": []}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from pinecone import GRPCVector, GRPCSparseValues\n",
    "from google.protobuf.struct_pb2 import Struct\n",
    "from tqdm import tqdm\n",
    "\n",
    "with pinecone.GRPCIndex(index_name) as index:\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch = df[i:min(i+batch_size, len(df))]\n",
    "        upserts = []\n",
    "        for row in batch.rows(named=True):\n",
    "            metadata = Struct()\n",
    "            metadata.update(dict(text=row['text']))\n",
    "            u = GRPCVector(\n",
    "                values=row['values'],\n",
    "                id=str(row['id']),\n",
    "                metadata=metadata, \n",
    "                sparse_values=GRPCSparseValues(**row['sparse_values'])\n",
    "            )\n",
    "            upserts.append(u)\n",
    "        r = index.upsert(vectors=upserts, async_req=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '1', 'score': 34.0199394, 'values': []},\n",
       "             {'id': '2', 'score': 30.4394989, 'values': []},\n",
       "             {'id': '260', 'score': 11.6323013, 'values': []},\n",
       "             {'id': '259', 'score': 9.89988232, 'values': []},\n",
       "             {'id': '498', 'score': 8.63788795, 'values': []},\n",
       "             {'id': '301', 'score': 8.40716457, 'values': []},\n",
       "             {'id': '202', 'score': 8.00751114, 'values': []},\n",
       "             {'id': '212', 'score': 7.43195486, 'values': []},\n",
       "             {'id': '403', 'score': 6.58435822, 'values': []},\n",
       "             {'id': '410', 'score': 6.3796258, 'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(id=\"1\", top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Query\n",
    "\n",
    "We use a weighted combination of sparse and dense query vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_score_norm(dense, sparse, alpha: float):\n",
    "    \"\"\"Hybrid score using a convex combination\n",
    "\n",
    "    alpha * dense + (1 - alpha) * sparse\n",
    "\n",
    "    Args:\n",
    "        dense: Array of floats representing\n",
    "        sparse: a dict of `indices` and `values`\n",
    "        alpha: scale between 0 and 1\n",
    "    \"\"\"\n",
    "    if alpha < 0 or alpha > 1:\n",
    "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "    hs = {\n",
    "        'indices': sparse['indices'],\n",
    "        'values':  [v * (1 - alpha) for v in sparse['values']]\n",
    "    }\n",
    "    return [v * alpha for v in dense], hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"how to invest in india\"\n",
    "sparse = splade(text)\n",
    "dense = model.encode(text).tolist()\n",
    "hdense, hsparse = hybrid_score_norm(dense, sparse, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '1',\n",
       "              'metadata': {'text': ' What is the step by step guide to invest '\n",
       "                                   'in share market in india?'},\n",
       "              'score': 4.3153429,\n",
       "              'values': []},\n",
       "             {'id': '260',\n",
       "              'metadata': {'text': ' How do I access Google.com from India?'},\n",
       "              'score': 2.86029983,\n",
       "              'values': []},\n",
       "             {'id': '2',\n",
       "              'metadata': {'text': ' What is the step by step guide to invest '\n",
       "                                   'in share market?'},\n",
       "              'score': 2.7389214,\n",
       "              'values': []},\n",
       "             {'id': '498',\n",
       "              'metadata': {'text': ' How can I best invest ₹5000 over the next '\n",
       "                                   '6 months?'},\n",
       "              'score': 2.55986595,\n",
       "              'values': []},\n",
       "             {'id': '259',\n",
       "              'metadata': {'text': ' How do I access Torbox in India?'},\n",
       "              'score': 2.49220681,\n",
       "              'values': []},\n",
       "             {'id': '301',\n",
       "              'metadata': {'text': ' How many years Britain ruled India?'},\n",
       "              'score': 2.03178906,\n",
       "              'values': []},\n",
       "             {'id': '497',\n",
       "              'metadata': {'text': ' What is the best way to invest $500 '\n",
       "                                   'legally so that I can get tangible profits '\n",
       "                                   'over a relatively short period of time, '\n",
       "                                   'say 6 months?'},\n",
       "              'score': 1.97877145,\n",
       "              'values': []},\n",
       "             {'id': '202',\n",
       "              'metadata': {'text': ' Will there be a nuclear war between India '\n",
       "                                   'and Pakistan?'},\n",
       "              'score': 1.94062543,\n",
       "              'values': []},\n",
       "             {'id': '212',\n",
       "              'metadata': {'text': ' How demonetisation could affect the GDP '\n",
       "                                   'of India in both short run and long run?'},\n",
       "              'score': 1.82189405,\n",
       "              'values': []},\n",
       "             {'id': '402',\n",
       "              'metadata': {'text': ' What is the best way to become a '\n",
       "                                   'billionaire?'},\n",
       "              'score': 1.69279063,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import SparseValues\n",
    "\n",
    "index.query(top_k=10, vector=hdense, sparse_vector=SparseValues(**hsparse), include_metadata=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
